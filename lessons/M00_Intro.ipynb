{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c5805b-e0bc-43ec-b9f3-12e54b0ee8fe",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Text preprocessing for flexible analysis\n",
    "\n",
    "DS 7800\n",
    "\n",
    "Raf Alvarado\n",
    "\n",
    "29 Februrary 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e3b02a-8359-4f63-bd29-2a741c3b44ba",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Da's Fallacy\n",
    "\n",
    "![](nanda.png)\n",
    "\n",
    "> [Nan Da 2019](https://www.journals.uchicago.edu/doi/full/10.1086/702594?journalCode=ci)\n",
    "\n",
    "This is incorrect.\n",
    "\n",
    "In CLS data work, the most import decisions are about **structure**.\n",
    "\n",
    "Structure is **geometry**.\n",
    "\n",
    "Counting without structure is meaningless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2f6cd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Two Approaches\n",
    "\n",
    "1. Work with **text collections**\n",
    "    - Requires prior existence\n",
    "    - Allows for many analytic pathways\n",
    "2. Work with **text extracts**\n",
    "    - Can be created in the process of doing research\n",
    "    - Allows for restricted analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945a7b77",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Data Models\n",
    "\n",
    "- In both cases, there are target data models\n",
    "- **Text Collections**\n",
    "    - LIB\n",
    "    \n",
    "    - TOKEN\n",
    "    - VOCAB\n",
    "- **Extracts**\n",
    "    - LIB\n",
    "    - EXTRACT\n",
    "    - ANNOTATION\n",
    "\n",
    "See [Lecture](https://docs.google.com/presentation/d/1JqEMMAygGLuvZGl_SSMgCdIkipTtJlgmiq8qCAhc_AY/edit?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bf5697-50dd-4edb-b191-6f37b4c892ec",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Steps\n",
    "\n",
    "1. **Collect** sources\n",
    "2. **Learn** structure\n",
    "3. **Parse** into tables\n",
    "4. **Annotate** for linguistic features\n",
    "5. **Vectorize** into analytic tables\n",
    "6. **Model** and **Visualize**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d6613-356a-40e1-8e67-4e21565ca1dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 1. Collect Sources\n",
    "\n",
    "- Curated digital collections\n",
    "- Web scraping\n",
    "- API\n",
    "- By hand"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ad4f8-e258-4c43-86f9-22210e275b4a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Example Collection Sites\n",
    "\n",
    "- [Faulkner](https://faulkner.drupal.shanti.virginia.edu/)\n",
    "- [Multepal](https://multepal.spanitalport.virginia.edu/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24019c7a-68f4-45c3-b495-069366cb21fb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 2. Learn Structure\n",
    "\n",
    "- Structure represenation varies by text type:\n",
    "    - Plain Text -- use of line breaks, punctuation, etc.\n",
    "    - XML -- DTD, Schema\n",
    "    - HTML -- Browser inspector\n",
    "- In each, trying to discover OHCO\n",
    "    - Ordered Hierarchy of Content Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf18906",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example: Project Gutenberg\n",
    "\n",
    "\n",
    "<div style=\"float:left;\">\n",
    "<pre>\n",
    "- BOOK\n",
    "    - Chapter 1 &larr; Single lines with the word \"Chapter\"\n",
    "        - Paragraph 1 &larr; Double line breaks\n",
    "            - Sentence 1 &larr; Punctuation\n",
    "            - Sentence 2\n",
    "            - ...\n",
    "        - Paragraph 2\n",
    "        - ...\n",
    "    - Chapter 2\n",
    "        - ...\n",
    "</pre>\n",
    "</div>\n",
    "<img src=\"sample-gutenberg.png\" width=\"500\" style=\"float:right;\">            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f737034",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Parse into tables\n",
    "\n",
    "- After learning the structure, choose tools and approach\n",
    "    - Every collection is different\n",
    "- Goal is to parse into tables:\n",
    "    - `LIBRARY`: A table with info about each text, e.g. title, date, author, etc.\n",
    "    - `DOC`: A table with a row for each parsed chunk of text.\n",
    "    - Or: `TOKEN`: A table with token as a row.\n",
    "    - `VOCAB`: A table with each unique word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0822ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Example\n",
    "\n",
    "![](M02TextModels.png)\n",
    "\n",
    "Example: [Importing _Persuasion_](https://github.com/ontoligent/DS5001-2024-01-R/blob/main/lessons/M02_TextModels/M02_01_Importing-Persuasion.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c42e99c-b581-4a94-b35a-8a734d488ddb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Annotate\n",
    "\n",
    "- Use NLP libraries (such as NLTK) to provide grammatical information\n",
    "    - Part-of-Speech for each token\n",
    "    - Most frequenct part-of-speech for each term\n",
    "    - Whether or not a term is a stopword\n",
    "    - Corpus frequency of a words\n",
    "    - Named Entities\n",
    "- Examples: \n",
    "    - [Annotating with NLTK](https://github.com/ontoligent/DS5001-2024-01-R/blob/main/lessons/M04_NLP/M04_00_NLTK_Intro.ipynb)\n",
    "    - [Annotating a small corpus](https://github.com/ontoligent/DS5001-2024-01-R/blob/main/lessons/M04_NLP/M04_01_Pipeline.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a942ef7b-a591-4570-8a52-fae71383fd75",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Vectorize\n",
    "\n",
    "- Convert DOC or TOKEN table into a \"bag-of-words\" representation (BOW)\n",
    "- Convert the BOW into a document-term matrix (DTM)\n",
    "- Convert into other vector spaces (e.g. time-token)\n",
    "- Apply TF-IDF to compute the signifance of words in documents and in the corpus \n",
    "- Examples: \n",
    "    - [BOW to TFIDF](https://github.com/ontoligent/DS5001-2024-01-R/blob/main/lessons/M05_VectorSpaceModels/M05_01_BOW_TFIDF.ipynb)\n",
    "    - [Time Token Matrix](https://github.com/ontoligent/DS5001-2024-01-R/blob/main/lessons/M05_VectorSpaceModels/M05_02_TimeTokenMatrices.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412caec-133b-4fb8-ad10-2ecb6b7d4ddc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Model and Visualize\n",
    "\n",
    "- One your text is in a vector space format, you can apply various models to it\n",
    "- Since each row is a vector in word space, you can measure distances between documents and words\n",
    "- These distance measures can be used to \"cluster\" documents and words in various ways\n",
    "- You can also apply methods like PCA (Principal Component Analysis) to the vector space to explore the deeper semantics of the corpus\n",
    "- Examples:\n",
    "    - [Hierarchical Clustering]()\n",
    "    - [PCA]()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "rise": {
   "theme": "sky"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
